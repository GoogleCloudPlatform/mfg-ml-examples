{
 "cells": [
  {
   "cell_type": "raw",
   "id": "81e231c2-5085-48ec-8096-be50f2ffea62",
   "metadata": {},
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d00795-f6ba-4d9d-a920-01f8232024c3",
   "metadata": {},
   "source": [
    "# Tool Wear Detection: Model Training\n",
    "\n",
    "In this notebook, you will predict CNC milling machine conditions by training a [Vertex AI AutoML tabular model](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/overview) using the public [Kaggle CNC Mill Tool Wear dataset](https://www.kaggle.com/datasets/shasun/tool-wear-detection-in-cnc-mill). \n",
    "\n",
    "This dataset is collected from running machining experiments on 2\" x 2\" x 1.5\" wax blocks in a CNC milling machine. The dataset contains measurements from 4 motors (X,Y, Z axes and spindle) and program values in the CNC machine. The measurements includes position, velocity, acceleration, and power consumptions across the 4 motors. \n",
    "\n",
    "For full detail of the dataset, please see [this](https://www.kaggle.com/datasets/shasun/tool-wear-detection-in-cnc-mill)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7715c6-9fbe-4456-a610-958a82299c79",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. Depending on your environment, there may be some warnings and errors that are safe to ignore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836179f-bab2-47da-ac22-a1c8e2458e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\") and not os.getenv(\"VIRTUAL_ENV\")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install fsspec gcsfs $USER_FLAG -q\n",
    "! pip3 install tensorflow-data-validation $USER_FLAG -q\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9f073-98b6-4dd6-a9be-223689214433",
   "metadata": {},
   "source": [
    "## Restart the kernel\n",
    "\n",
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa37f6-d141-4ba4-9734-cce01d04d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1502d-f5ec-49d0-b2a3-a064886fcada",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e737a-f5b2-459f-9a13-bbda3a8f3fa7",
   "metadata": {},
   "source": [
    "### Set your project ID\n",
    "\n",
    "If you don't know your project ID, you may be able to get your project ID using gcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba68d3-bb82-4298-a453-44384ad35669",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b07de0-0b52-48b3-af70-a562639d5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a347a-595a-42b7-bd6b-66bd8395dcda",
   "metadata": {},
   "source": [
    "### Region\n",
    "\n",
    "You can also change the `REGION` variable, which is used for operations throughout the rest of this notebook. Below are regions supported for Vertex AI. It is recommended that you choose the region closest to you.\n",
    "\n",
    "- Americas: `us-central1`\n",
    "- Europe: `europe-west4`\n",
    "- Asia Pacific: `asia-east1`\n",
    "\n",
    "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
    "\n",
    "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a57cf-0c21-45c9-9612-7a09135df252",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # @param {type: \"string\"}\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\"\n",
    "\n",
    "print(\"Region:\", REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f014796-6e75-420f-bccd-1c78868ead53",
   "metadata": {},
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "In this notebook, you will be creating a Vertex AI dataset for training a Vertex AI tabular model. Before you can create a Vertex AI dataset, you will upload the processed data to a Cloud Storage bucket.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. It must be unique across all Cloud Storage buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73474db1-492d-4f87-adb4-4a10e4a03de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561d605-a0d8-4769-8d35-d1bcdfb8380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUCKET_URI == \"\" or BUCKET_URI is None or BUCKET_URI == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_URI = \"gs://\" + PROJECT_ID + \"-ml\"\n",
    "\n",
    "print(\"BUCKET_URI:\", BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791def6-5f8e-463e-a8e0-5913ad6dbe0e",
   "metadata": {},
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1b632-6011-4919-9370-6ffbeb899573",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e3f10-fbf8-4aa1-a3fd-1cd5e3c726b8",
   "metadata": {},
   "source": [
    "Finally, validate access to your Cloud Storage bucket by examining its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d39f8-b47c-416c-a932-d8bc1c874932",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b05aa-1365-422f-a4c7-c363c3059b8c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bfbeb0-355b-471b-a5d3-3e8191a481f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.cloud.aiplatform as vertex_ai\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(40, 20))\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e221345-7d85-4364-b48f-1157bb0fdd0f",
   "metadata": {},
   "source": [
    "## Initialize varabiles and Vertex AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1286288-217c-457a-bfd3-3c3ecb283c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local file path to dataset\n",
    "LOCAL_DATA_PATH = \"./data\"\n",
    "# GCS path to dataset\n",
    "GCS_DATA_PATH = \"tool_wear/\"\n",
    "# Label column name\n",
    "LABEL_COL = \"tool_condition\"\n",
    "# Split column name\n",
    "SPLIT_COL = \"ml_use\"\n",
    "# Vertex AI artifacts prefix\n",
    "VERTEX_AI_PREFIX = \"tool_wear\"  # TODO: change me\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249f14d-a0c5-406c-a750-483aa3006ad9",
   "metadata": {},
   "source": [
    "## Download and extract dataset\n",
    "\n",
    "Download the [Kaggle CNC Mill Tool Wear dataset](https://www.kaggle.com/datasets/shasun/tool-wear-detection-in-cnc-mill) from a public Cloud Storage bucket and extract the zip file locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5690006-3a00-450a-8536-4a135db44477",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $LOCAL_DATA_PATH\n",
    "! gsutil cp gs://gc-mde-demo-public/tool_wear_dataset.zip $LOCAL_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edbe85-e78c-4d04-b888-cfde8e7cfbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(f\"{LOCAL_DATA_PATH}/tool_wear_dataset.zip\", \"r\") as zipObj:\n",
    "    # Extract all the contents of zip file in current directory\n",
    "    zipObj.extractall(LOCAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092e97d-4a6a-44f7-b507-d14e6112a3d1",
   "metadata": {},
   "source": [
    "## Merge data files\n",
    "\n",
    "You will merge the data files into a single dataframe.\n",
    "\n",
    "As described in [Kaggle](https://www.kaggle.com/datasets/shasun/tool-wear-detection-in-cnc-mill), this dataset contains a `train.csv` that contains the general data about each experiments. The time series data collected for each experiement are stored in `experiment_[01-18].csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a88a52-da1d-47e1-bbdc-9695c68bd55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv = pd.read_csv(os.path.join(LOCAL_DATA_PATH, \"train.csv\"))\n",
    "\n",
    "df_train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea4b97-37cc-4d45-af67-eb5284aadac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = list(df_train_csv[\"No\"].unique())\n",
    "\n",
    "li_df_experiments = []\n",
    "\n",
    "for id in experiment_ids:\n",
    "    filename = (\n",
    "        f\"experiment_{id:0>2d}.csv\"  # Pad number with zeros (left padding, width 2)\n",
    "    )\n",
    "    df = pd.read_csv(os.path.join(LOCAL_DATA_PATH, filename), index_col=None)\n",
    "    df[\"No\"] = id\n",
    "    df = df.merge(df_train_csv, how=\"left\", on=\"No\")\n",
    "    print(f\"experiment id: {id} | shape: {df.shape}\")\n",
    "\n",
    "    li_df_experiments.append(df)\n",
    "\n",
    "df_experiments = pd.concat(li_df_experiments, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb44f58-9153-41d8-a138-31930349f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb1094-0da3-4120-bb88-36e4d68bf842",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "In this section, you will explore and learn the characteristics of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d087bf-f8a6-4a7c-b84d-127c94ebbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b988b6-f5cc-4bbd-adfe-8c0fb9d0a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8e517-1070-4401-9297-291d768c074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "stats = tfdv.generate_statistics_from_dataframe(\n",
    "    dataframe=df_experiments,\n",
    "    stats_options=tfdv.StatsOptions(\n",
    "        label_feature=LABEL_COL, sample_rate=1, num_top_values=50\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6526e6f-8855-449b-91f7-28a94a47b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdv.visualize_statistics(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fc95b-be9f-45f7-9754-f5fafdf688f7",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Here are some observations noted from the EDA.\n",
    "\n",
    "1. There are some numerical columns (e.g. `Z1_CurrentFeedback`, `Z1_DCBusVoltage`) where there are only zeros.\n",
    "1. There are some numerical columns (e.g. `Z1_CommandVelocity`, `Z1_CommandAcceleration`) where more than 50% of the values are zeros.\n",
    "1. Some of the actual and command values have more than 50% of discrepancy in their values. For example, `X1_CommandAcceleration` contains 73.12% of zeros while `X1_ActualAcceleration` has 13.66% of zeros. \n",
    "1. `S1_SystemInertia` has a constant value of `12` across all data points. \n",
    "1. `passed_visual_inspection` has missing values.\n",
    "1. The number of data points across `worn` (i.e. 13308) and `unworn` (i.e. 11978) classes are relatively balanced. \n",
    "\n",
    "Take some time and think about what other observations did you make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281eca7f-4468-4bfd-b817-25fefceaaa73",
   "metadata": {},
   "source": [
    "## Explore experiments across different outcomes\n",
    "\n",
    "This dataset provides 2 different observed outcomes from the CNC milling operations:\n",
    "\n",
    "1. `machining_finalized`: indicator for whether machining was completed without the workpiece moving out of the pneumatic vise\n",
    "1. `passed_visual_inspection`: indicator for whether the workpiece passed visual inspection, only available for experiments where machining was completed\n",
    "\n",
    "You will explore the distribution of experiments and data points across different observed outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1c048-f0ed-4909-8006-aa9221fea548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv_na = df_train_csv.fillna(\"no\")\n",
    "df_train_csv_na.groupby(\n",
    "    [\"tool_condition\", \"machining_finalized\", \"passed_visual_inspection\"]\n",
    ").No.apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c44e23-ecc6-4933-96cf-998cf74788ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments_na = df_experiments.fillna(\"no\")\n",
    "df_experiments_na[\n",
    "    [\"tool_condition\", \"machining_finalized\", \"passed_visual_inspection\"]\n",
    "].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43f488-f0c4-4593-a9fc-f660ea7dff65",
   "metadata": {},
   "source": [
    "## Data visualizations\n",
    "\n",
    "Data visualizations are helpful when analyzing data. Data visualizations make it easier to identify patterns, trends and outliers in datasets.\n",
    "\n",
    "In this section, you will visualize different features in the CNC Mill dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e24e2",
   "metadata": {},
   "source": [
    "### Visualize categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8db8bb-154c-4b5a-a019-426767808094",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axs[1, 2].set_visible(False)\n",
    "\n",
    "df_experiments[\"M1_CURRENT_PROGRAM_NUMBER\"].value_counts().plot(\n",
    "    kind=\"bar\", title=\"M1_CURRENT_PROGRAM_NUMBER\", ax=axs[0, 0]\n",
    ")\n",
    "df_experiments[\"M1_CURRENT_FEEDRATE\"].value_counts().plot(\n",
    "    kind=\"bar\", title=\"M1_CURRENT_FEEDRATE\", ax=axs[0, 1]\n",
    ")\n",
    "df_experiments[\"Machining_Process\"].value_counts().plot(\n",
    "    kind=\"bar\", title=\"Machining_Process\", ax=axs[0, 2]\n",
    ")\n",
    "df_experiments[\"feedrate\"].value_counts().plot(\n",
    "    kind=\"bar\", title=\"feedrate\", ax=axs[1, 0]\n",
    ")\n",
    "df_experiments[\"clamp_pressure\"].value_counts().plot(\n",
    "    kind=\"bar\", title=\"clamp_pressure\", ax=axs[1, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748be73",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. For `M1_CURRENT_PROGRAM_NUMBER`, there are imbalance of count across the categories with high density when `M1_CURRENT_PROGRAM_NUMBER` is `1.0`.\n",
    "1. For `Machining_Process`, values `end` and `Starting` have low count.\n",
    "1. `M1_CURRENT_FEEDRATE` and `feedrate` have similar distribution except that `M1_CURRENT_FEEDRATE` contains an additional category (`50.0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85e154",
   "metadata": {},
   "source": [
    "### Visualize correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f3194-11b9-46c8-b8e3-45a46556fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 40))\n",
    "\n",
    "# Plot pairwise correlation for numerical columns\n",
    "sns.heatmap(df_experiments.corr(), cbar=True, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d415c4",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. There are many highly correlated features.\n",
    "    - Across X / Y / Z / S\n",
    "        - `*_ActualPosition` & `*_CommandPosition`\n",
    "        - `*_ActualVelocity` & `*_CommandVelocity`\n",
    "        - `*_DCBusVoltage` & `*_OutputCurrent` & `*_OutputVoltage` & `*_OutputPower`\n",
    "    - `{X,Y,Z}_*Positions` have negative correlation with `S1_{ActualVelocity,CurrentFeedback,DCBusVoltage,OutputVoltage,OutputPower}`.\n",
    "1. There are some features (e.g. `Z1_CurrentFeedback`, `S1_SystemInertia`) with no correlation because these features contains constant value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924393f3",
   "metadata": {},
   "source": [
    "### Visualize numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f5f5f-f389-4571-80ce-d1c3ab47680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    df: pd.DataFrame, experiment_ids: list, metric: str, color: str = \"#00FF00\"\n",
    "):\n",
    "    n_plots = len(experiment_ids)\n",
    "    n_cols = 3\n",
    "    n_rows = n_plots // n_cols + 1\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(16, 14))\n",
    "\n",
    "    for i in range(n_plots):\n",
    "        exp_id = experiment_ids[i]\n",
    "        df_metric = df[df[\"No\"] == exp_id].reset_index()[metric]\n",
    "        df_metric.plot(\n",
    "            kind=\"line\",\n",
    "            title=f\"{metric} in experiment {exp_id}\",\n",
    "            color=color,\n",
    "            ax=axs[i // n_cols, i % n_cols],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4243006-72ab-4b63-b6ee-bea4685e92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph various metrics by label and experiments\n",
    "agg = df_train_csv.groupby([LABEL_COL])[\"No\"].apply(list)\n",
    "\n",
    "worn_exp_ids = agg[\"worn\"]\n",
    "unworn_exp_ids = agg[\"unworn\"]\n",
    "\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b2acf-50c7-4f55-86d0-5683e9cb4fcb",
   "metadata": {},
   "source": [
    "### Actual Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bdecf-7a5b-4865-99ec-a67a07a34c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    df=df_experiments,\n",
    "    experiment_ids=unworn_exp_ids,\n",
    "    metric=\"Z1_ActualVelocity\",\n",
    "    color=\"green\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe348d6b-f2fd-4389-8b08-6ea9dffe7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    df=df_experiments,\n",
    "    experiment_ids=worn_exp_ids,\n",
    "    metric=\"Z1_ActualVelocity\",\n",
    "    color=\"red\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc1f32-22dc-45aa-8f34-cd04b42a31fa",
   "metadata": {},
   "source": [
    "### Actual Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ed721-ab69-4d25-a0ae-6b942aa6370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    df=df_experiments,\n",
    "    experiment_ids=unworn_exp_ids,\n",
    "    metric=\"Z1_ActualPosition\",\n",
    "    color=\"green\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cceb3f7-5d91-455d-b886-e33fb0f81fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    df=df_experiments,\n",
    "    experiment_ids=worn_exp_ids,\n",
    "    metric=\"Z1_ActualPosition\",\n",
    "    color=\"red\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba313f",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. It is not intuitive to distinguish worn and unworn CNC mills from their the telemetries (e.g. `*_ActualVelocity`, `*_ActualPosition`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eafbd4-0eed-4754-8048-74a556799caf",
   "metadata": {},
   "source": [
    "### EDA Summary\n",
    "\n",
    "1. There are some feature columns (e.g. `Z1_CurrentFeedback`,`Z1_CommandVelocity`) with high percentage of zeros. \n",
    "1. The number of data points across `worn` (i.e. 13308) and `unworn` (i.e. 11978) classes are relatively balanced. \n",
    "1. There are some highly correlated features (e.g. `*_ActualPosition` and `*_CommandPosition`) and some features (e.g. `Z1_CurrentFeedback`, `S1_SystemInertia`) with no correlation.\n",
    "1. It is not intuitive to distinguish worn and unworn CNC mills from their the telemetries (e.g. `*_ActualVelocity`, `*_ActualPosition`). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede24a5e-80da-4a59-99c7-a3b58dbfa7ca",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Vertex AI AutoML is a no-code & lo-code end-to-end model training pipeline that includes automatic data splitting, feature engineering, architecture search, model training, model ensembling, and model distillation. AutoML lets you create and train a model with minimal technical effort. You can use AutoML to quickly prototype models and explore new datasets before investing in development. You can further customize AutoML for classification and regression tasks using [Vertex AI Tabluar Workflow](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/overview). \n",
    "\n",
    "In constrast to training custom machine learning models, AutoML does many [data preparation](https://cloud.google.com/vertex-ai/docs/datasets/data-types-tabular) tasks (e.g. one-hot encoding and feature scaling) for you. Hence, it is important to learn your responsibility in data preparation when using AutoML. See [this](https://cloud.google.com/vertex-ai/docs/datasets/data-types-tabular) for the full list of AutoML data transformations. \n",
    "\n",
    "In this section, you will prepare the CNC Mill dataset following the [Vertex AI tabular data preparation best practices](https://cloud.google.com/vertex-ai/docs/datasets/bp-tabular)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e667c-d7c1-422b-a008-1cfb5542b56d",
   "metadata": {},
   "source": [
    "### [Avoid Data Leakage](https://cloud.google.com/vertex-ai/docs/datasets/bp-tabular#target-leakage)\n",
    "\n",
    "Target leakage happens when your training data includes predictive information that is not available when you ask for a prediction. Target leakage can cause your model to show excellent evaluation metrics, but perform poorly on real data.\n",
    "\n",
    "For this dataset, there are 2 leaking features: `machining_finalized` and `passed_visual_inspection`. These features are not known when the machining operation is in progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959f53c-d0e0-4ef7-a3e7-7d91c492445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_TO_EXCLUDE = [\"machining_finalized\", \"passed_visual_inspection\"]\n",
    "\n",
    "df_experiments.drop(columns=COL_TO_EXCLUDE, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c4569-3bc8-4eb9-88c9-b560e568fa35",
   "metadata": {},
   "source": [
    "### [Make sure your categorical features are accurate and clean](https://cloud.google.com/vertex-ai/docs/datasets/bp-tabular#make_sure_your_categorical_features_are_accurate_and_clean)\n",
    "\n",
    "Data inconsistencies can cause categories to be incorrectly split. For example, if your data includes \"Brown\" and \"brown\", Vertex AI uses those values as separate categories, when you might have intended them to be the same. Misspellings can have a similar effect.\n",
    "\n",
    "For the `Machining_Process` feature, there are some misspelled and inconsistent categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189d995-f3a2-4992-a297-38240ecc9962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments[\"Machining_Process\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feafdcf6-29c1-4676-9da5-045a3d5dfe7e",
   "metadata": {},
   "source": [
    "#### Clean Up Machining Process\n",
    "\n",
    "Notice the values `End` and `end` represents the same process, but have different capitalization. This will cause [AutoML](https://cloud.google.com/vertex-ai/docs/datasets/data-types-tabular#categorical-transf) to treat these as different values. Hence, we will relabel the value `end` to `End`. \n",
    "\n",
    "In addition, notice that `Starting` value only has 1 count. There isn't sufficient data points to provide insights on the `Starting` process and may confuse the model prediction. Hence, we will group `Starting` and `Prep` together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8bc47-2b19-4568-acac-675bd7dce83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments.replace(\n",
    "    {\"Machining_Process\": {\"Starting\": \"Prep\", \"end\": \"End\"}}, inplace=True\n",
    ")\n",
    "\n",
    "df_experiments[\"Machining_Process\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb63faa-2b17-4c2b-960e-86557b2730bf",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "[Feature engineering](https://developers.google.com/machine-learning/glossary#feature_engineering) is the process of determining which features might be useful in training a model, and then creating those features by transforming the raw data. \n",
    "\n",
    "Feature engineering is an important part of the data science lifecycle because having predictive features is key to high model performance. For the CNC mill dataset, you will create a set of new features by calculating the difference between the command and actual metrics. The hypothesis is that the difference between the command and actual metrics is indicative of tool conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d322aa8-402a-48bf-9bd7-0c5917a23d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [\"X1\", \"Y1\", \"Z1\", \"S1\"]\n",
    "metrics = [\"Position\", \"Velocity\", \"Acceleration\"]\n",
    "\n",
    "for ax in axes:\n",
    "    for metric in metrics:\n",
    "        df_experiments[f\"{ax}_{metric}Diff\"] = abs(\n",
    "            df_experiments[f\"{ax}_Command{metric}\"]\n",
    "            - df_experiments[f\"{ax}_Actual{metric}\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e838ec-db63-4256-b405-0e491da5ea21",
   "metadata": {},
   "source": [
    "## Holdout data for simulation\n",
    "\n",
    "In order to simulate CNC milling machine telemetries from the edge, you will create a flow in [Manufacturing Connect edge (MCe)](https://litmusdocs.mcoutput.com/1379100/Content/MCe-Installation&Configuration/c-edgs-overview.htm) to generate sample CNC milling machine telemetries. Hence, you will split 500 records from both experiment 2 (tool_condition: `unworn`) and experiment 13 (tool_condition: `worn`) for simulation. \n",
    "\n",
    "> Note: the MCe flow definition is included in this repository. You can directly import the flow definition without having to worry about the holdout data. However, it is important to **exclude** the holdout data from the training data so the AutoML model doesn't train on the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f3f15d-5835-4a58-90f9-9d82bad3f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiment_2_holdout = df_experiments[df_experiments[\"No\"] == 2].iloc[-500:]\n",
    "df_experiment_13_holdout = df_experiments[df_experiments[\"No\"] == 13].iloc[-500:]\n",
    "indices_exclude = list(df_experiment_2_holdout.index) + list(\n",
    "    df_experiment_13_holdout.index\n",
    ")\n",
    "\n",
    "df_experiments.drop(index=indices_exclude, inplace=True)\n",
    "\n",
    "df_experiment_holdout = pd.concat(\n",
    "    [df_experiment_2_holdout, df_experiment_13_holdout], axis=0, ignore_index=True\n",
    ")\n",
    "\n",
    "dataset_bucket_uri = f\"{BUCKET_URI}/{GCS_DATA_PATH}{VERTEX_AI_PREFIX}_holdout.json\"\n",
    "\n",
    "df_experiment_holdout.drop(columns=[\"No\"], errors=\"ignore\", inplace=True)\n",
    "df_experiment_holdout.drop(columns=[\"material\"], errors=\"ignore\", inplace=True)\n",
    "df_experiment_holdout.to_json(dataset_bucket_uri, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7502d-798b-4bfe-b526-311cd5b80084",
   "metadata": {},
   "source": [
    "## [Using a manual split](https://cloud.google.com/vertex-ai/docs/datasets/bp-tabular#consider_using_a_manual_split)\n",
    "\n",
    "Vertex AI selects the rows for the train and test dataset randomly (but deterministically). For imbalanced classes, you could end up with a small number of the minority class in your test dataset, or even none, which causes training to fail.\n",
    "\n",
    "As seen in the [EDA](#Exploratory-data-analysis) section, the target classes are relatively balanced (11978 `unworn` and 13308 `worn` records). However, each experiment in the CNC mill dataset is an independent machining operation. Hence, it is not optimal to include subset of experiments in both train and test datasets as it may leak information about the machining operation. Another way to rationalize this concept is to understand how this model will be used in production. Will the model predict on past machining operations that the model is trained on? Or will the model predict on new machining operations?\n",
    "\n",
    "> When splitting data, it is important to consider how your models will be used in production as that will give you insight on how to properly split train and test datasets, without leaking information about the target class.\n",
    "\n",
    "One of the ways to manually split data in AutoML is to [use the ml_use label](https://cloud.google.com/vertex-ai/docs/general/ml-use#ml-use). In this case, we are adding the following experiments in the test dataset while treating other experiments as training dataset:\n",
    "\n",
    "| Experiment | tool_condition | machining_finalized | passed_visual_inspection |\n",
    "|------------|----------------|---------------------|--------------------------|\n",
    "| 1          | unworn         | yes                 | yes                      |\n",
    "| 4          | unworn         | no                  | no                       |\n",
    "| 7          | worn           | no                  | no                       |\n",
    "| 8          | worn           | no                  | no                       |\n",
    "| 15         | worn           | yes                 | yes                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc38f6-a7ab-4e5a-9fcd-f4054a8efbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp 1: unworn, finalized, pass\n",
    "# Exp 4: unworn, not finalized, no pass\n",
    "# Exp 7: worn, not finalized, no pass\n",
    "# Exp 8: worn, not finalized, no pass\n",
    "# Exp 15: worn, finalized, pass\n",
    "test_experiment_ids = [1, 4, 7, 8, 15]\n",
    "\n",
    "df_experiments[SPLIT_COL] = \"UNASSIGNED\"\n",
    "df_experiments.loc[df_experiments[\"No\"].isin(test_experiment_ids), SPLIT_COL] = \"TEST\"\n",
    "df_experiments[SPLIT_COL].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa2563-0761-4adc-ba95-9b2f8fde91b4",
   "metadata": {},
   "source": [
    "## Export processed data to Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be40486-bb12-41cc-a1f1-51292aeafecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop experiment id column\n",
    "df_experiments_out = df_experiments.drop(columns=[\"No\"], errors=\"ignore\")\n",
    "dataset_bucket_uri = f\"{BUCKET_URI}/{GCS_DATA_PATH}{VERTEX_AI_PREFIX}.csv\"\n",
    "\n",
    "df_experiments_out.to_csv(dataset_bucket_uri, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec595f4-0c51-4151-ac63-ba82680d0adf",
   "metadata": {},
   "source": [
    "## [Create Vertex AI tabular dataset](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/create-dataset)\n",
    "\n",
    "You will create a Vertex AI dataset for training an AutoML model using the processed data in Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b8fdd-4e8b-4868-8e22-d258969170fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vertex AI dataset\n",
    "dataset = vertex_ai.TabularDataset.create(\n",
    "    display_name=VERTEX_AI_PREFIX,\n",
    "    gcs_source=dataset_bucket_uri,\n",
    ")\n",
    "\n",
    "print(dataset.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dcf96-a052-4226-8f45-44adc549ee92",
   "metadata": {},
   "source": [
    "## [Train an AutoML classification model](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/train-model#aiplatform_create_training_pipeline_tabular_classification_sample-python)\n",
    "\n",
    "You will train an AutoML classification model using the Vertex AI dataset you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cd4f7-6751-4682-9a86-420eaf958a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMATION = [\n",
    "    {\"numeric\": {\"column_name\": \"X1_ActualPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_ActualVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_ActualAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_CommandPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_CommandVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_CommandAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_CurrentFeedback\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_DCBusVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_OutputCurrent\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_OutputVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_OutputPower\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_ActualPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_ActualVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_ActualAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_CommandPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_CommandVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_CommandAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_CurrentFeedback\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_DCBusVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_OutputCurrent\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_OutputVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_OutputPower\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_ActualPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_ActualVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_ActualAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_CommandPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_CommandVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_CommandAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_CurrentFeedback\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_DCBusVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_OutputCurrent\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_OutputVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_ActualPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_ActualVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_ActualAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_CommandPosition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_CommandVelocity\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_CommandAcceleration\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_CurrentFeedback\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_DCBusVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_OutputCurrent\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_OutputVoltage\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_OutputPower\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_SystemInertia\"}},\n",
    "    {\"categorical\": {\"column_name\": \"M1_CURRENT_PROGRAM_NUMBER\"}},\n",
    "    {\"categorical\": {\"column_name\": \"M1_sequence_number\"}},\n",
    "    {\"numeric\": {\"column_name\": \"M1_CURRENT_FEEDRATE\"}},\n",
    "    {\"categorical\": {\"column_name\": \"Machining_Process\"}},\n",
    "    {\"categorical\": {\"column_name\": \"material\"}},\n",
    "    {\"numeric\": {\"column_name\": \"feedrate\"}},\n",
    "    {\"numeric\": {\"column_name\": \"clamp_pressure\"}},\n",
    "    {\"categorical\": {\"column_name\": \"tool_condition\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_PositionDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_VelocityDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"X1_AccelerationDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_PositionDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_VelocityDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Y1_AccelerationDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_PositionDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_VelocityDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"Z1_AccelerationDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_PositionDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_VelocityDiff\"}},\n",
    "    {\"numeric\": {\"column_name\": \"S1_AccelerationDiff\"}},\n",
    "    {\"categorical\": {\"column_name\": \"ml_use\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894522a1-7647-4693-8c6f-8a2564a11ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vertex AI AutoML job\n",
    "dag = vertex_ai.AutoMLTabularTrainingJob(\n",
    "    display_name=VERTEX_AI_PREFIX,\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    optimization_objective=\"maximize-au-roc\",\n",
    "    column_transformations=TRANSFORMATION,\n",
    ")\n",
    "\n",
    "model = dag.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=VERTEX_AI_PREFIX,\n",
    "    predefined_split_column_name=SPLIT_COL,\n",
    "    budget_milli_node_hours=1000,\n",
    "    disable_early_stopping=False,\n",
    "    target_column=LABEL_COL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a996c5",
   "metadata": {},
   "source": [
    "> Note: The Vertex AI AutoML tabular job may run for 2+ hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78afe3-adf3-44a7-ba52-033150fccd0e",
   "metadata": {},
   "source": [
    "## Validate model\n",
    "\n",
    "You will validate the model by:\n",
    "\n",
    "1. [Deploying the model to an endpoint for online prediction](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#aiplatform_create_endpoint_sample-python)\n",
    "1. Use the endpoint to predict a `worn` and `unworn` record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2a4c6-5369-4779-8dca-cf916958465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    machine_type=\"n1-standard-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f19f0c-7548-4c30-a971-7cfc65a6f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_feature_attributions(explanations, k=5):\n",
    "    feat_attr = list(explanations[0].attributions[0].feature_attributions.items())\n",
    "    return sorted(feat_attr, key=lambda x: abs(x[1]), reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b199c8-551e-4ec5-8821-1923801e57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unworn_dict = df_experiments[df_experiments[\"No\"] == 17].iloc[0].astype(\"str\").to_dict()\n",
    "\n",
    "unworn_pred = endpoint.explain(instances=[unworn_dict])\n",
    "\n",
    "print(unworn_pred.predictions)\n",
    "print(top_k_feature_attributions(unworn_pred.explanations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e02f38-528a-45c9-95e7-ba81c8f283eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "worn_dict = df_experiments[df_experiments[\"No\"] == 18].iloc[0].astype(\"str\").to_dict()\n",
    "\n",
    "worn_pred = endpoint.explain(instances=[worn_dict])\n",
    "\n",
    "print(worn_pred.predictions)\n",
    "print(top_k_feature_attributions(worn_pred.explanations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f1319",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. The online predictions return [prediction](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#interpret_prediction_results) and [explanation](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#interpret_explanation_results) results.\n",
    "1. [Prediction](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#interpret_prediction_results) results include the class labels and respective confidence scores. The confidence score communicates how strongly your model associates each class label with an item. The higher the number, the higher the model's confidence that the label should be applied to that item.\n",
    "1. [Explanation](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#interpret_explanation_results) results include the [feature attribution](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-explanations) values for each features. In this case, you only see the top 5 attributing features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a993969-e2d9-449a-98c5-01f7deb6d351",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bf686-d98b-4747-bb9e-0c0c1f51a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files_to_remove = glob.glob(os.path.join(LOCAL_DATA_PATH, \"*.csv\"))\n",
    "files_to_remove += glob.glob(os.path.join(LOCAL_DATA_PATH, \"*.txt\"))\n",
    "files_to_remove += glob.glob(os.path.join(LOCAL_DATA_PATH, \"*.jpg\"))\n",
    "\n",
    "for f in files_to_remove:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222334a7-b225-4223-b549-edb6bc60c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()\n",
    "endpoint.delete()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('3.7.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "01786fb03733d89bd2c78a575886e6b66950215f353ab2d24fad9198de693c3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
